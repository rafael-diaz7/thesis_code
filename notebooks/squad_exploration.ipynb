{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-05T07:03:21.127072300Z",
     "start_time": "2023-12-05T07:03:18.793740100Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "file_path = \"../data/squad-train-v1.1.json\"\n",
    "with open(file_path, 'r') as f:\n",
    "    data = json.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T07:03:21.551992100Z",
     "start_time": "2023-12-05T07:03:21.127072300Z"
    }
   },
   "id": "a13d734d352a5267"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "[{'answer_start': 515, 'text': 'Saint Bernadette Soubirous'}]"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['data'][0]['paragraphs'][0]['qas'][0]['answers']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T07:03:21.558985300Z",
     "start_time": "2023-12-05T07:03:21.551992100Z"
    }
   },
   "id": "7f4b595820dadb34"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "questions = []\n",
    "contexts = []\n",
    "answers = []\n",
    "answer_starts = []\n",
    "for i in data['data']:\n",
    "    for paragraph in i['paragraphs']:\n",
    "        for qas in paragraph['qas']:\n",
    "            questions.append(qas['question'])\n",
    "            contexts.append(paragraph['context'])\n",
    "            answers.append(qas['answers'][0]['text'])\n",
    "            answer_starts.append(qas['answers'][0]['answer_start'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T07:03:21.618648200Z",
     "start_time": "2023-12-05T07:03:21.557984400Z"
    }
   },
   "id": "dff60d32dcbcf3cc"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "                                            question  \\\n0  To whom did the Virgin Mary allegedly appear i...   \n1  What is in front of the Notre Dame Main Building?   \n2  The Basilica of the Sacred heart at Notre Dame...   \n3                  What is the Grotto at Notre Dame?   \n4  What sits on top of the Main Building at Notre...   \n\n                                             context  \\\n0  Architecturally, the school has a Catholic cha...   \n1  Architecturally, the school has a Catholic cha...   \n2  Architecturally, the school has a Catholic cha...   \n3  Architecturally, the school has a Catholic cha...   \n4  Architecturally, the school has a Catholic cha...   \n\n                                    answer  answer_start  \n0               Saint Bernadette Soubirous           515  \n1                a copper statue of Christ           188  \n2                        the Main Building           279  \n3  a Marian place of prayer and reflection           381  \n4       a golden statue of the Virgin Mary            92  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question</th>\n      <th>context</th>\n      <th>answer</th>\n      <th>answer_start</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>To whom did the Virgin Mary allegedly appear i...</td>\n      <td>Architecturally, the school has a Catholic cha...</td>\n      <td>Saint Bernadette Soubirous</td>\n      <td>515</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>What is in front of the Notre Dame Main Building?</td>\n      <td>Architecturally, the school has a Catholic cha...</td>\n      <td>a copper statue of Christ</td>\n      <td>188</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n      <td>Architecturally, the school has a Catholic cha...</td>\n      <td>the Main Building</td>\n      <td>279</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>What is the Grotto at Notre Dame?</td>\n      <td>Architecturally, the school has a Catholic cha...</td>\n      <td>a Marian place of prayer and reflection</td>\n      <td>381</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>What sits on top of the Main Building at Notre...</td>\n      <td>Architecturally, the school has a Catholic cha...</td>\n      <td>a golden statue of the Virgin Mary</td>\n      <td>92</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'question': questions, 'context': contexts, 'answer': answers, 'answer_start': answer_starts})\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T07:03:21.642620Z",
     "start_time": "2023-12-05T07:03:21.594118500Z"
    }
   },
   "id": "1f1dea9520c8ac09"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "df.to_csv('../data/squad-train-v1.1.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T16:07:01.649277300Z",
     "start_time": "2023-12-01T16:07:00.252251500Z"
    }
   },
   "id": "a1a0024b9a4a1001"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# test first five rows of data\n",
    "test = df.iloc[:5]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T07:03:22.717060100Z",
     "start_time": "2023-12-05T07:03:22.709542400Z"
    }
   },
   "id": "45813df79b5f7e28"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 5 examples gave 5 features.\n",
      "Here is where each comes from: [0, 1, 2, 3, 4].\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(test['question'].tolist(), test['context'].tolist(), truncation='only_second',\n",
    "                   stride=50, return_overflowing_tokens=True, return_offsets_mapping=True)\n",
    "print(f\"The 5 examples gave {len(inputs['input_ids'])} features.\")\n",
    "print(f\"Here is where each comes from: {inputs['overflow_to_sample_mapping']}.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T16:11:02.183629800Z",
     "start_time": "2023-12-01T16:11:02.173613900Z"
    }
   },
   "id": "6ad28e0a8282325"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "515 541\n",
      "Saint Bernadette Soubirous\n",
      "17 179\n",
      "188 213\n",
      "a copper statue of Christ\n",
      "13 175\n",
      "279 296\n",
      "the Main Building\n",
      "17 179\n",
      "381 420\n",
      "a Marian place of prayer and reflection\n",
      "12 174\n",
      "92 126\n",
      "a golden statue of the Virgin Mary\n",
      "14 176\n"
     ]
    },
    {
     "data": {
      "text/plain": "([152, 69, 99, 117, 50], [158, 73, 101, 123, 56])"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_positions = []\n",
    "end_positions = []\n",
    "\n",
    "for i, offset in enumerate(inputs[\"offset_mapping\"]):\n",
    "    sample_idx = inputs[\"overflow_to_sample_mapping\"][i]\n",
    "    answer = test['answer'][sample_idx]\n",
    "    start_char = test[\"answer_start\"][sample_idx]\n",
    "    end_char = test[\"answer_start\"][sample_idx] + len(answer)\n",
    "    print(start_char, end_char)\n",
    "    print(answer)\n",
    "    sequence_ids = inputs.sequence_ids(i)\n",
    "\n",
    "    # Find the start and end of the context]\n",
    "    idx = 0\n",
    "    while sequence_ids[idx] != 1:\n",
    "        idx += 1\n",
    "    context_start = idx\n",
    "    while sequence_ids[idx] == 1:\n",
    "        idx += 1\n",
    "    context_end = idx - 1\n",
    "    print(context_start, context_end)\n",
    "\n",
    "    # If the answer is not fully inside the context, label is (0, 0)\n",
    "    if offset[context_start][0] > start_char or offset[context_end][1] < end_char:\n",
    "        start_positions.append(0)\n",
    "        end_positions.append(0)\n",
    "    else:\n",
    "        # Otherwise it's the start and end token positions\n",
    "        adder = next(i for i in range(len(inputs['input_ids'][0])) if inputs['input_ids'][0][i] == 102)\n",
    "        idx = context_start\n",
    "        while idx <= context_end and offset[idx][0 ] <= start_char:\n",
    "            idx += 1\n",
    "        start_positions.append(adder + idx - 1)\n",
    "\n",
    "        idx = context_end\n",
    "        while idx >= context_start and offset[idx][1] >= end_char:\n",
    "            idx -= 1\n",
    "        end_positions.append(adder + idx + 1)\n",
    "\n",
    "start_positions, end_positions"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T17:05:58.617920300Z",
     "start_time": "2023-12-01T17:05:58.608871900Z"
    }
   },
   "id": "a68e3de9d03988a"
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 101\n",
      "Theoretical answer: the Main Building, labels give: ##lica is the\n"
     ]
    }
   ],
   "source": [
    "idx = 2\n",
    "sample_idx = inputs[\"overflow_to_sample_mapping\"][idx]\n",
    "answer = test['answer'][idx]\n",
    "\n",
    "start = start_positions[idx] \n",
    "end = end_positions[idx] \n",
    "print(start, end)\n",
    "labeled_answer = tokenizer.decode(inputs[\"input_ids\"][idx][start : end + 1])\n",
    "\n",
    "print(f\"Theoretical answer: {answer}, labels give: {labeled_answer}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T16:29:29.765927400Z",
     "start_time": "2023-12-01T16:29:29.755904100Z"
    }
   },
   "id": "502019d6fae69d12"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "def preprocess_function(test):\n",
    "    inputs = tokenizer(\n",
    "        test['question'].tolist(),\n",
    "        test['context'].tolist(),\n",
    "        max_length=384,\n",
    "        truncation=\"only_second\",\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
    "    answers = test['answer'].tolist()\n",
    "    answer_starts = test['answer_start'].tolist()\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "\n",
    "    for i, offset in enumerate(offset_mapping):\n",
    "        start_char = answer_starts[i]\n",
    "        end_char = start_char + len(answers[i])\n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "\n",
    "        # Find the start and end of the context\n",
    "        idx = 0\n",
    "        while sequence_ids[idx] != 1:\n",
    "            idx += 1\n",
    "        context_start = idx\n",
    "        while sequence_ids[idx] == 1:\n",
    "            idx += 1\n",
    "        context_end = idx - 1\n",
    "\n",
    "        # If the answer is not fully inside the context, label it (0, 0)\n",
    "        if offset[context_start][0] > end_char or offset[context_end][1] < start_char:\n",
    "            start_positions.append(0)\n",
    "            end_positions.append(0)\n",
    "        else:\n",
    "            # Otherwise it's the start and end token positions\n",
    "            idx = context_start\n",
    "            while idx <= context_end and offset[idx][0] <= start_char:\n",
    "                idx += 1\n",
    "            start_positions.append(idx - 1)\n",
    "\n",
    "            idx = context_end\n",
    "            while idx >= context_start and offset[idx][1] >= end_char:\n",
    "                idx -= 1\n",
    "            end_positions.append(idx + 1)\n",
    "\n",
    "    inputs[\"start_positions\"] = start_positions\n",
    "    inputs[\"end_positions\"] = end_positions\n",
    "    return inputs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T07:11:49.265485Z",
     "start_time": "2023-12-05T07:11:49.252678300Z"
    }
   },
   "id": "a24f58095596880d"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saint Bernadette Soubirous\n",
      "a copper statue of Christ\n",
      "the Main Building\n",
      "a Marian place of prayer and reflection\n",
      "a golden statue of the Virgin Mary\n"
     ]
    }
   ],
   "source": [
    "inp = preprocess_function(test)\n",
    "starts = inp[\"start_positions\"]\n",
    "ends = inp[\"end_positions\"]\n",
    "for ind, (s, e) in enumerate(zip(starts, ends)):\n",
    "    print(tokenizer.decode(inp[\"input_ids\"][ind][s:e+1]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T07:11:50.025307900Z",
     "start_time": "2023-12-05T07:11:50.018127100Z"
    }
   },
   "id": "a81f2f7c96eb8481"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "0                 Saint Bernadette Soubirous\n1                  a copper statue of Christ\n2                          the Main Building\n3    a Marian place of prayer and reflection\n4         a golden statue of the Virgin Mary\nName: answer, dtype: object"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.answer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T07:06:28.299910800Z",
     "start_time": "2023-12-05T07:06:28.291207300Z"
    }
   },
   "id": "ac00eb88223327c2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "11cbb1bb7d0dd683"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
